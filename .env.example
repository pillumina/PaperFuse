# =====================================
# Supabase (Optional - Production)
# =====================================
# If these are not set, PaperFuse uses local JSON file storage
# Get these from your Supabase project settings
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# =====================================
# LLM Provider Configuration
# =====================================
# Options: claude, glm
# Default: glm (ZhipuAI - more cost-effective for Chinese users)
LLM_PROVIDER=glm

# ---------------------------------
# Anthropic Claude
# ---------------------------------
# Required if LLM_PROVIDER=claude
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key

# Optional: Specify custom models
# Default quick model: claude-haiku (fast, cost-effective for classification)
# Default deep model: claude-sonnet (high-quality analysis)
CLAUDE_QUICK_MODEL=claude-haiku
CLAUDE_DEEP_MODEL=claude-sonnet

# --------------------------
# ZhipuAI GLM (Recommended)
# --------------------------
# Required if LLM_PROVIDER=glm
# Get your API key from: https://open.bigmodel.cn/
ZHIPUAI_API_KEY=your_zhipuai_api_key

# Optional: Specify custom models
#
# Quick models (for classification and scoring):
# - glm-4.5-flash (DEFAULT, FREE) - Fastest, good for quick tasks
# - glm-4.5-x - Very fast, lightweight
# - glm-4.5-air - Value-priced, balanced
# - glm-4.5-airx - Faster, economical
#
# Deep models (for detailed analysis):
# - glm-4.7 (DEFAULT) - Flagship quality, best analysis
# - glm-4.6 - Ultra, faster deep analysis
# - glm-4.5 - Pro, economy deep analysis
GLM_QUICK_MODEL=glm-4.5-flash
GLM_DEEP_MODEL=glm-4.7

# =====================================
# Topics Configuration (Optional)
# =====================================
# Custom research topics for paper classification and UI display.
#
# This is a JSON array defining your research topics. Each topic has:
# - key: Unique identifier (stored in database, used in API calls)
# - label: Display name shown in UI (buttons, badges, etc.)
# - description: Detailed description used by LLM for classification
# - color: Tailwind CSS classes for badge styling (light + dark mode)
#
# If not set, falls back to default topics: RL, LLM, Inference
#
# Format (single line, properly escaped):
# TOPICS_CONFIG='[{"key":"rl","label":"Reinforcement Learning","description":"...","color":"..."},{"key":"llm",...}]'
#
# For multi-line format (requires proper JSON escaping):
# TOPICS_CONFIG='[{"key":"rl","label":"Reinforcement Learning","description":"RL algorithms, training methods, exploration, exploitation, policy optimization, value functions, actor-critic, PPO, DQN, SARSA, reward shaping, hierarchical RL, etc.","color":"bg-purple-100 text-purple-800 dark:bg-purple-900 dark:text-purple-200"},{"key":"llm","label":"Large Language Models","description":"LLM architecture, training, alignment, capabilities, language models, transformers for NLP, GPT, BERT, T5, scaling laws, pre-training, fine-tuning, instruction tuning, etc.","color":"bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200"},{"key":"inference","label":"Inference & Systems","description":"LLM inference optimization, quantization, distillation, serving systems, vLLM, TensorRT-LLM, deployment, latency optimization, throughput improvements, batch processing, etc.","color":"bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200"}]'
TOPICS_CONFIG='[
  {
    "key": "rl",
    "label": "Reinforcement Learning",
    "description": "RL algorithms, training methods, exploration, exploitation, policy optimization, value functions, actor-critic, PPO, DQN, SARSA, reward shaping, hierarchical RL, etc.",
    "color": "bg-purple-100 text-purple-800 dark:bg-purple-900 dark:text-purple-200"
  },
  {
    "key": "llm",
    "label": "Large Language Models",
    "description": "LLM architecture, training, alignment, capabilities, language models, transformers for NLP, GPT, BERT, T5, scaling laws, pre-training, fine-tuning, instruction tuning, etc.",
    "color": "bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200"
  },
  {
    "key": "inference",
    "label": "Inference & Systems",
    "description": "LLM inference optimization, quantization, distillation, serving systems, vLLM, TensorRT-LLM, deployment, latency optimization, throughput improvements, batch processing, etc.",
    "color": "bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200"
  }
]'

# =====================================
# ArXiv Configuration
# =====================================
# Comma-separated list of ArXiv categories to fetch papers from
# Common AI/ML categories:
# - cs.AI - Artificial Intelligence
# - cs.LG - Machine Learning
# - cs.CL - Computation and Language (NLP)
# - cs.RO - Robotics (often RL-related)
# - cs.CV - Computer Vision (often multimodal)
# - stat.ML - Statistics - Machine Learning
#
# Default: cs.AI,cs.LG,stat.ML
ARXIV_CATEGORIES=cs.AI,cs.LG,stat.ML
# ARXIV_CATEGORIES=cs.AI,cs.LG,cs.CL,cs.RO,stat.ML

# =====================================
# Analysis Configuration
# =====================================
# Enable/disable LLM analysis
# Set to true to enable AI-powered paper classification, scoring, and analysis
# When false, papers are still fetched but not analyzed
# Default: false
ENABLE_LLM_ANALYSIS=false

# Analysis depth determines how much of the paper is analyzed
# Options:
# - basic: Abstract only (fastest, no LaTeX download)
# - standard: Introduction + conclusion for scoring, full text if score >= threshold (recommended)
# - full: Full text with model deciding detailed output based on score
# Default: standard
ANALYSIS_DEPTH=standard

# Minimum score threshold for detailed output
#
# In STANDARD mode:
# - Papers with score >= this threshold get Phase 2 analysis (full detailed analysis)
# - Phase 2 includes: all sections, algorithms, formulas, diagrams
# - Range: 1-10, recommended: 7-8
#
# In FULL mode:
# - Determines whether to include algorithms/formulas/diagrams in output
# - Higher threshold = only best papers get detailed visual content
# - Range: 1-10, recommended: 7-9
# Default: 7
MIN_SCORE_THRESHOLD=8

# Optional: Minimum score to save paper
# Papers with score below this threshold are skipped during fetch
# Set to null or comment out to save all papers
# Useful for filtering out low-quality papers early
# Range: 1-10, recommended: 5-6
# Default: null (save all papers)
MIN_SCORE_TO_SAVE=6

# =====================================
# Paper Cache (LaTeX Source)
# =====================================
# Directory to store downloaded LaTeX source files
# Used for full text analysis when ANALYSIS_DEPTH is standard or full
# LaTeX sources provide better content than PDF extraction
# Default: ./local/cache/papers
PAPER_CACHE_PATH=./local/cache/papers

# =====================================
# Cron Job Security
# =====================================
# Secret key to protect cron job endpoints
# Required for production deployment with Vercel Cron
# Generate a random string: openssl rand -base64 32
CRON_SECRET=generate_a_random_secret_string_here
